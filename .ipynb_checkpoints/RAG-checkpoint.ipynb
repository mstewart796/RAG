{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23594862-0e4a-49dc-804e-2297202264bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b02220-44fd-4bc0-99bb-1f3cceebcf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for langchain\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "063babd5-c3ed-4556-8bcb-afd3f12e9f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "MODEL_COMMAND_R = 'command-r'\n",
    "MODEL_COMMAND_R7B = 'command-r7b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c5df37-a543-4bdc-890a-da9308a94f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e22f73f-c6ef-4e14-81b9-7add9ce04a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in documents using LangChain's loaders\n",
    "# Take everything in all the sub-folders of our knowledgebase\n",
    "\n",
    "folders = glob.glob(\"RAG-docs/*\") # In other tests I had more than one folder inside RAG-docs\n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c63d8f7a-4370-454a-9ccd-ce70b05b95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting using chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35a0e754-ac8d-4924-8d6e-9075b8754de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document types found: q-and-a\n"
     ]
    }
   ],
   "source": [
    "doc_types = set(chunk.metadata['doc_type'] for chunk in chunks)\n",
    "print(f\"Document types found: {', '.join(doc_types)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30b8f863-f5d7-4da4-85b5-263423bf178d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv('../.env',override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d14fabb-c1b1-42cf-a870-ca8c7824ad66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mstew\\AppData\\Local\\Temp\\ipykernel_11896\\3409896792.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c41d077f-a409-4783-b05f-44ac512dac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a Chroma Datastore already exists - if so, delete the collection to start from scratch\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abf00fc3-882c-4fb0-8adf-763fc9770efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 20 documents\n"
     ]
    }
   ],
   "source": [
    "# Create our Chroma vectorstore!\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b61e057e-82cf-4cf6-a6d6-77250a11dd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LLM\n",
    "llm = OllamaLLM(model=MODEL_COMMAND_R7B)\n",
    "\n",
    "# Define memory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Define the retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2}) \n",
    "\n",
    "# Define a custom system message\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    D√™ respostas precisas e com c√≥digo quando for dispon√≠vel nos documentos.\n",
    "    Atenda de forma simp√°tica e personalizada, como um bom atendente de clientes.\n",
    "    Se n√£o souber a resposta, diga isso. N√£o invente informa√ß√µes se n√£o tiver contexto relevante.\n",
    "    Voc√™ responde em portugu√™s. Mesmo que a pergunta seja feita em ingl√™s, voc√™ SEMPRE responde em portugu√™s.\n",
    "                \n",
    "    Aqui est√° o contexto relevante para ajudar a responder: {context}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Define the human message template\n",
    "human_message = HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "\n",
    "# Create a chat prompt template with both the system and human messages\n",
    "custom_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "\n",
    "# Create the conversation chain with a custom prompt\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": custom_prompt}  # Pass the fixed prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c18bc83-fa4e-408e-8f0e-c22208783ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a new conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# putting it together: set up the conversation chain with the LLM, the vector store and memory\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, \n",
    "                                                           retriever=retriever, \n",
    "                                                           memory=memory,\n",
    "                                                          combine_docs_chain_kwargs={\"prompt\": custom_prompt}\n",
    "                                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "708f5e18-8887-4a28-a09f-720a8fc7caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(question, history):\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46075333-bae0-4017-b462-6817cab849bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Launch Gradio:\n",
    "memory.clear() # I was having issues with memory not resetting between different chats\n",
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9f6b3b8-dea2-4811-b650-98da9648c17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Query: Como corrigir um erro de SQL?\n",
      "\n",
      "üìÑ Document 1: **Escalation:**\n",
      "- If authentication issues persist, check authentication method (e.g., database authentication vs. LDAP).\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Performance Issues\n",
      "\n",
      "### **Issue: High CPU Utilization in Oracle Database**\n",
      "**Symptoms:**\n",
      "- Queries running slower than expected\n",
      "- CPU usage consistently above 90%\n",
      "\n",
      "**Troubleshooting Steps:**\n",
      "1. Identify top CPU-consuming sessions:\n",
      "   ```sql\n",
      "   SELECT s.sid, s.serial#, p.spid, s.username, s.program, t.sql_id\n",
      "   FROM v$session s JOIN v$process p ON s.paddr = p.addr\n",
      "...\n",
      "\n",
      "\n",
      "üìÑ Document 2: ---\n",
      "\n",
      "## 1. Query Optimization\n",
      "\n",
      "### **Issue: Slow Query Execution**\n",
      "**Symptoms:**\n",
      "- Queries taking too long to execute\n",
      "- High CPU usage when running queries\n",
      "- Locking or contention issues\n",
      "\n",
      "**Optimization Steps:**\n",
      "1. Analyze query execution plan:\n",
      "   ```sql\n",
      "   EXPLAIN PLAN FOR <your-query>;\n",
      "   SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);\n",
      "   ```\n",
      "2. Identify missing indexes and create them:\n",
      "   ```sql\n",
      "   CREATE INDEX idx_column_name ON table_name(column_name);\n",
      "   ```\n",
      "3. Rewrite queries using optimized SQL...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mstew\\AppData\\Local\\Temp\\ipykernel_11896\\2347217504.py:11: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Model Response: {'question': 'Como corrigir um erro de SQL?', 'chat_history': [HumanMessage(content='Como corrigir um erro de SQL?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Quais s√£o os passos para configurar uma nova inst√¢ncia?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Existe um m√©todo recomendado para otimizar a performance do banco?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Como corrigir um erro de SQL?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={})], 'answer': '8888888888888888888888888888888'}\n",
      "\n",
      "\n",
      "üîé Query: Quais s√£o os passos para configurar uma nova inst√¢ncia?\n",
      "\n",
      "üìÑ Document 1: **Escalation:**\n",
      "- If restoration fails, escalate to Oracle Cloud Infrastructure support.\n",
      "\n",
      "---\n",
      "\n",
      "## 6. Escalation Matrix\n",
      "\n",
      "| Issue Category | Initial Troubleshooting | Escalation Level 1 | Escalation Level 2 |\n",
      "|---------------|----------------------|------------------|------------------|\n",
      "| Connection Issues | Check listener, logs | DBA | Network Team |\n",
      "| Performance Issues | Analyze SQL, check CPU | Performance Tuning Team | System Administrators |\n",
      "| Backup Failures | Check RMAN logs, disk space | ...\n",
      "\n",
      "\n",
      "üìÑ Document 2: ---\n",
      "\n",
      "### **Issue: ORA-28001: The Password Has Expired**\n",
      "**Symptoms:**\n",
      "- Login fails due to expired password\n",
      "- \"ORA-28001: The password has expired\" message\n",
      "\n",
      "**Possible Causes:**\n",
      "- User password policy enforces expiration\n",
      "- Password not reset within allowed period\n",
      "\n",
      "**Solution:**\n",
      "1. Log in as a DBA user and reset the password:\n",
      "   ```sql\n",
      "   ALTER USER username IDENTIFIED BY new_password;\n",
      "   ```\n",
      "2. Modify password expiration policy if necessary:\n",
      "   ```sql\n",
      "   ALTER PROFILE default LIMIT PASSWORD_LIFE...\n",
      "\n",
      "üìù Model Response: {'question': 'Quais s√£o os passos para configurar uma nova inst√¢ncia?', 'chat_history': [HumanMessage(content='Como corrigir um erro de SQL?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Quais s√£o os passos para configurar uma nova inst√¢ncia?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Existe um m√©todo recomendado para otimizar a performance do banco?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Como corrigir um erro de SQL?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Quais s√£o os passos para configurar uma nova inst√¢ncia?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={})], 'answer': '8888888888888888888888888888888'}\n",
      "\n",
      "\n",
      "üîé Query: Existe um m√©todo recomendado para otimizar a performance do banco?\n",
      "\n",
      "üìÑ Document 1: ---\n",
      "\n",
      "## 7. Storage Optimization\n",
      "\n",
      "### **Issue: High Disk I/O Usage**\n",
      "**Symptoms:**\n",
      "- Slow disk read/write operations\n",
      "- High I/O wait times impacting database performance\n",
      "\n",
      "**Optimization Steps:**\n",
      "1. Monitor disk I/O performance:\n",
      "   ```sql\n",
      "   SELECT * FROM v$sysstat WHERE name LIKE 'physical%read%';\n",
      "   ```\n",
      "2. Use Oracle Automatic Storage Management (ASM) for disk management.\n",
      "3. Implement tablespace compression to reduce storage usage:\n",
      "   ```sql\n",
      "   ALTER TABLE table_name COMPRESS;\n",
      "   ```\n",
      "4. Move fre...\n",
      "\n",
      "\n",
      "üìÑ Document 2: # Performance Optimization Guides\n",
      "\n",
      "## Overview\n",
      "This document provides best practices and techniques for optimizing the performance of Oracle Cloud and Oracle Database environments. It includes tuning strategies for queries, indexing, memory management, and cloud resource allocation.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Query Optimization\n",
      "\n",
      "### **Issue: Slow Query Execution**\n",
      "**Symptoms:**\n",
      "- Queries taking too long to execute\n",
      "- High CPU usage when running queries\n",
      "- Locking or contention issues...\n",
      "\n",
      "üìù Model Response: {'question': 'Existe um m√©todo recomendado para otimizar a performance do banco?', 'chat_history': [HumanMessage(content='Como corrigir um erro de SQL?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Quais s√£o os passos para configurar uma nova inst√¢ncia?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Existe um m√©todo recomendado para otimizar a performance do banco?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Como corrigir um erro de SQL?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Quais s√£o os passos para configurar uma nova inst√¢ncia?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Existe um m√©todo recomendado para otimizar a performance do banco?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={})], 'answer': '8888888888888888888888888888888'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_queries = [\n",
    "    \"Como corrigir um erro de SQL?\",\n",
    "    \"Quais s√£o os passos para configurar uma nova inst√¢ncia?\",\n",
    "    \"Existe um m√©todo recomendado para otimizar a performance do banco?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nüîé Query: {query}\")\n",
    "    \n",
    "    # Retrieve documents BEFORE sending to LLM\n",
    "    retrieved_docs = retriever.get_relevant_documents(query)\n",
    "    \n",
    "    if not retrieved_docs:\n",
    "        print(\"‚ö†Ô∏è No documents retrieved for this query!\")\n",
    "    else:\n",
    "        for i, doc in enumerate(retrieved_docs[:3]):  # Print first 3 docs for brevity\n",
    "            print(f\"\\nüìÑ Document {i+1}: {doc.page_content[:500]}...\\n\")\n",
    "\n",
    "    # Invoke the conversational retrieval chain\n",
    "    response = conversation_chain.invoke({\"question\": query})\n",
    "    \n",
    "    print(f\"üìù Model Response: {response}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "556736c2-6a97-4447-83d8-2c7cf5905381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mstew\\AppData\\Local\\Temp\\ipykernel_11896\\4002882078.py:1: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm(\"Explique o erro ORA-12541 e como resolv√™-lo.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Direct LLM Response: 8888888888888888888888888888888\n"
     ]
    }
   ],
   "source": [
    "response = llm(\"Explique o erro ORA-12541 e como resolv√™-lo.\")\n",
    "print(f\"üì° Direct LLM Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a075dd-e17c-4b0c-85d9-6f3683bf7672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
