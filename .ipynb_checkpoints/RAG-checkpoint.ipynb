{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23594862-0e4a-49dc-804e-2297202264bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b02220-44fd-4bc0-99bb-1f3cceebcf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for langchain\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "063babd5-c3ed-4556-8bcb-afd3f12e9f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "MODEL_COMMAND_R = 'command-r'\n",
    "MODEL_COMMAND_R7B = 'command-r7b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c5df37-a543-4bdc-890a-da9308a94f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e22f73f-c6ef-4e14-81b9-7add9ce04a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in documents using LangChain's loaders\n",
    "# Take everything in all the sub-folders of our knowledgebase\n",
    "\n",
    "folders = glob.glob(\"RAG-docs/*\") # In other tests I had more than one folder inside RAG-docs\n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c63d8f7a-4370-454a-9ccd-ce70b05b95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting using chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35a0e754-ac8d-4924-8d6e-9075b8754de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document types found: q-and-a\n"
     ]
    }
   ],
   "source": [
    "doc_types = set(chunk.metadata['doc_type'] for chunk in chunks)\n",
    "print(f\"Document types found: {', '.join(doc_types)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30b8f863-f5d7-4da4-85b5-263423bf178d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv('../.env',override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d14fabb-c1b1-42cf-a870-ca8c7824ad66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mstew\\AppData\\Local\\Temp\\ipykernel_11896\\3409896792.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c41d077f-a409-4783-b05f-44ac512dac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a Chroma Datastore already exists - if so, delete the collection to start from scratch\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abf00fc3-882c-4fb0-8adf-763fc9770efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 20 documents\n"
     ]
    }
   ],
   "source": [
    "# Create our Chroma vectorstore!\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b61e057e-82cf-4cf6-a6d6-77250a11dd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LLM\n",
    "llm = OllamaLLM(model=MODEL_COMMAND_R7B)\n",
    "\n",
    "# Define memory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Define the retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2}) \n",
    "\n",
    "# Define a custom system message\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Dê respostas precisas e com código quando for disponível nos documentos.\n",
    "    Atenda de forma simpática e personalizada, como um bom atendente de clientes.\n",
    "    Se não souber a resposta, diga isso. Não invente informações se não tiver contexto relevante.\n",
    "    Você responde em português. Mesmo que a pergunta seja feita em inglês, você SEMPRE responde em português.\n",
    "                \n",
    "    Aqui está o contexto relevante para ajudar a responder: {context}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Define the human message template\n",
    "human_message = HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "\n",
    "# Create a chat prompt template with both the system and human messages\n",
    "custom_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "\n",
    "# Create the conversation chain with a custom prompt\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": custom_prompt}  # Pass the fixed prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c18bc83-fa4e-408e-8f0e-c22208783ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a new conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# putting it together: set up the conversation chain with the LLM, the vector store and memory\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, \n",
    "                                                           retriever=retriever, \n",
    "                                                           memory=memory,\n",
    "                                                          combine_docs_chain_kwargs={\"prompt\": custom_prompt}\n",
    "                                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "708f5e18-8887-4a28-a09f-720a8fc7caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(question, history):\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46075333-bae0-4017-b462-6817cab849bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Launch Gradio:\n",
    "memory.clear() # I was having issues with memory not resetting between different chats\n",
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9f6b3b8-dea2-4811-b650-98da9648c17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Query: Como corrigir um erro de SQL?\n",
      "\n",
      "📄 Document 1: **Escalation:**\n",
      "- If authentication issues persist, check authentication method (e.g., database authentication vs. LDAP).\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Performance Issues\n",
      "\n",
      "### **Issue: High CPU Utilization in Oracle Database**\n",
      "**Symptoms:**\n",
      "- Queries running slower than expected\n",
      "- CPU usage consistently above 90%\n",
      "\n",
      "**Troubleshooting Steps:**\n",
      "1. Identify top CPU-consuming sessions:\n",
      "   ```sql\n",
      "   SELECT s.sid, s.serial#, p.spid, s.username, s.program, t.sql_id\n",
      "   FROM v$session s JOIN v$process p ON s.paddr = p.addr\n",
      "...\n",
      "\n",
      "\n",
      "📄 Document 2: ---\n",
      "\n",
      "## 1. Query Optimization\n",
      "\n",
      "### **Issue: Slow Query Execution**\n",
      "**Symptoms:**\n",
      "- Queries taking too long to execute\n",
      "- High CPU usage when running queries\n",
      "- Locking or contention issues\n",
      "\n",
      "**Optimization Steps:**\n",
      "1. Analyze query execution plan:\n",
      "   ```sql\n",
      "   EXPLAIN PLAN FOR <your-query>;\n",
      "   SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);\n",
      "   ```\n",
      "2. Identify missing indexes and create them:\n",
      "   ```sql\n",
      "   CREATE INDEX idx_column_name ON table_name(column_name);\n",
      "   ```\n",
      "3. Rewrite queries using optimized SQL...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mstew\\AppData\\Local\\Temp\\ipykernel_11896\\2347217504.py:11: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Model Response: {'question': 'Como corrigir um erro de SQL?', 'chat_history': [HumanMessage(content='Como corrigir um erro de SQL?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Quais são os passos para configurar uma nova instância?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Existe um método recomendado para otimizar a performance do banco?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Como corrigir um erro de SQL?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={})], 'answer': '8888888888888888888888888888888'}\n",
      "\n",
      "\n",
      "🔎 Query: Quais são os passos para configurar uma nova instância?\n",
      "\n",
      "📄 Document 1: **Escalation:**\n",
      "- If restoration fails, escalate to Oracle Cloud Infrastructure support.\n",
      "\n",
      "---\n",
      "\n",
      "## 6. Escalation Matrix\n",
      "\n",
      "| Issue Category | Initial Troubleshooting | Escalation Level 1 | Escalation Level 2 |\n",
      "|---------------|----------------------|------------------|------------------|\n",
      "| Connection Issues | Check listener, logs | DBA | Network Team |\n",
      "| Performance Issues | Analyze SQL, check CPU | Performance Tuning Team | System Administrators |\n",
      "| Backup Failures | Check RMAN logs, disk space | ...\n",
      "\n",
      "\n",
      "📄 Document 2: ---\n",
      "\n",
      "### **Issue: ORA-28001: The Password Has Expired**\n",
      "**Symptoms:**\n",
      "- Login fails due to expired password\n",
      "- \"ORA-28001: The password has expired\" message\n",
      "\n",
      "**Possible Causes:**\n",
      "- User password policy enforces expiration\n",
      "- Password not reset within allowed period\n",
      "\n",
      "**Solution:**\n",
      "1. Log in as a DBA user and reset the password:\n",
      "   ```sql\n",
      "   ALTER USER username IDENTIFIED BY new_password;\n",
      "   ```\n",
      "2. Modify password expiration policy if necessary:\n",
      "   ```sql\n",
      "   ALTER PROFILE default LIMIT PASSWORD_LIFE...\n",
      "\n",
      "📝 Model Response: {'question': 'Quais são os passos para configurar uma nova instância?', 'chat_history': [HumanMessage(content='Como corrigir um erro de SQL?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Quais são os passos para configurar uma nova instância?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Existe um método recomendado para otimizar a performance do banco?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Como corrigir um erro de SQL?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Quais são os passos para configurar uma nova instância?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={})], 'answer': '8888888888888888888888888888888'}\n",
      "\n",
      "\n",
      "🔎 Query: Existe um método recomendado para otimizar a performance do banco?\n",
      "\n",
      "📄 Document 1: ---\n",
      "\n",
      "## 7. Storage Optimization\n",
      "\n",
      "### **Issue: High Disk I/O Usage**\n",
      "**Symptoms:**\n",
      "- Slow disk read/write operations\n",
      "- High I/O wait times impacting database performance\n",
      "\n",
      "**Optimization Steps:**\n",
      "1. Monitor disk I/O performance:\n",
      "   ```sql\n",
      "   SELECT * FROM v$sysstat WHERE name LIKE 'physical%read%';\n",
      "   ```\n",
      "2. Use Oracle Automatic Storage Management (ASM) for disk management.\n",
      "3. Implement tablespace compression to reduce storage usage:\n",
      "   ```sql\n",
      "   ALTER TABLE table_name COMPRESS;\n",
      "   ```\n",
      "4. Move fre...\n",
      "\n",
      "\n",
      "📄 Document 2: # Performance Optimization Guides\n",
      "\n",
      "## Overview\n",
      "This document provides best practices and techniques for optimizing the performance of Oracle Cloud and Oracle Database environments. It includes tuning strategies for queries, indexing, memory management, and cloud resource allocation.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Query Optimization\n",
      "\n",
      "### **Issue: Slow Query Execution**\n",
      "**Symptoms:**\n",
      "- Queries taking too long to execute\n",
      "- High CPU usage when running queries\n",
      "- Locking or contention issues...\n",
      "\n",
      "📝 Model Response: {'question': 'Existe um método recomendado para otimizar a performance do banco?', 'chat_history': [HumanMessage(content='Como corrigir um erro de SQL?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Quais são os passos para configurar uma nova instância?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Existe um método recomendado para otimizar a performance do banco?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Como corrigir um erro de SQL?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Quais são os passos para configurar uma nova instância?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={}), HumanMessage(content='Existe um método recomendado para otimizar a performance do banco?', additional_kwargs={}, response_metadata={}), AIMessage(content='8888888888888888888888888888888', additional_kwargs={}, response_metadata={})], 'answer': '8888888888888888888888888888888'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_queries = [\n",
    "    \"Como corrigir um erro de SQL?\",\n",
    "    \"Quais são os passos para configurar uma nova instância?\",\n",
    "    \"Existe um método recomendado para otimizar a performance do banco?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n🔎 Query: {query}\")\n",
    "    \n",
    "    # Retrieve documents BEFORE sending to LLM\n",
    "    retrieved_docs = retriever.get_relevant_documents(query)\n",
    "    \n",
    "    if not retrieved_docs:\n",
    "        print(\"⚠️ No documents retrieved for this query!\")\n",
    "    else:\n",
    "        for i, doc in enumerate(retrieved_docs[:3]):  # Print first 3 docs for brevity\n",
    "            print(f\"\\n📄 Document {i+1}: {doc.page_content[:500]}...\\n\")\n",
    "\n",
    "    # Invoke the conversational retrieval chain\n",
    "    response = conversation_chain.invoke({\"question\": query})\n",
    "    \n",
    "    print(f\"📝 Model Response: {response}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "556736c2-6a97-4447-83d8-2c7cf5905381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mstew\\AppData\\Local\\Temp\\ipykernel_11896\\4002882078.py:1: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm(\"Explique o erro ORA-12541 e como resolvê-lo.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📡 Direct LLM Response: 8888888888888888888888888888888\n"
     ]
    }
   ],
   "source": [
    "response = llm(\"Explique o erro ORA-12541 e como resolvê-lo.\")\n",
    "print(f\"📡 Direct LLM Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a075dd-e17c-4b0c-85d9-6f3683bf7672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
